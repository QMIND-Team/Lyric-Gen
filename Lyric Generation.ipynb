{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from string import ascii_lowercase\n",
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Dense\n",
    "\n",
    "# from __future__ import print_function\n",
    "# from keras.callbacks import ModelCheckpoint\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, Activation, Dropout\n",
    "# from keras.layers import LSTM\n",
    "# from keras.optimizers import RMSprop, Adam\n",
    "# from keras.utils.data_utils import get_file\n",
    "\n",
    "# import random\n",
    "# import sys\n",
    "# import io\n",
    "# \n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# %matplotlib inline\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist = 'Kanye West'\n",
    "songs = pd.read_csv('Data/' + artist.lower().replace(' ', '_') + '_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_chars = list(ascii_lowercase)\n",
    "good_chars.append(\" \")\n",
    "good_chars.append(\".\")\n",
    "good_chars.append(\",\")\n",
    "good_chars.append(\"'\")\n",
    "\n",
    "char_to_int = dict((c, i) for i, c in enumerate(good_chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(good_chars))\n",
    "\n",
    "len(char_to_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract relevant data\n",
    "\n",
    "Uses the sliding door technique to create new dataframe. All lyrics are split into multiple segments of seed_len (40) characters each. These segments are saved into the new dataframe as a seed. The output is the next character in the lyrics.\n",
    "\n",
    "For example, assume seed_len is 20 and lyric is \"look at her face, its a wonderful face\":\n",
    "* \"look at her face, it\", 115 (unicode of \"s\" is 115)\n",
    "* \"ook at her face, its\", 32 (unicode of \" \" is 32)\n",
    "* \"ok at her face, its \", 97 (unicode of \"a\" is 97)\n",
    "* \"k at her face, its a\", 32 (unicode of \" \" is 32)\n",
    "* \" at her face, its a\", 119 (unicode of \"w\" is 119)\n",
    "* etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "415046"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ''\n",
    "\n",
    "for i, row in songs['lyrics'].iteritems():\n",
    "    clean = str(row).lower().replace(' ', '\\n')\n",
    "    text = text + \" \".join(re.findall(r\"[a-z']+\", clean))\n",
    "\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "414946"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_len = 100\n",
    "step = 1\n",
    "seeds = []\n",
    "outputs = []\n",
    "\n",
    "for i in range(0, len(text) - seed_len, step):\n",
    "    seeds.append(text[i: i + seed_len])\n",
    "    outputs.append(text[i + seed_len])\n",
    "    \n",
    "len(seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  should have my own reality show called soul survivor i stole on live er niggas than you you's a bit\n",
      "Output: c\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.utils import shuffle\n",
    "seeds, outputs = shuffle(seeds, outputs, random_state=0)\n",
    "\n",
    "print('Seed: ' + seeds[0])\n",
    "print('Output: ' + outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((len(seeds), seed_len, len(good_chars)), dtype=np.bool)\n",
    "y = np.zeros((len(seeds), len(good_chars)), dtype=np.bool)\n",
    "\n",
    "for i, seed in enumerate(seeds):\n",
    "    for t, char in enumerate(seed):\n",
    "        x[i, t, char_to_int[char]] = 1\n",
    "    y[i, char_to_int[outputs[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the AI\n",
    "\n",
    "### Creating the model\n",
    "Uses a Long-Short-Term-Memory (LSTM) network to predict the output from the seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model: a single LSTM\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(128, input_shape=(seed_len, len(good_chars))))\n",
    "# model.add(Dense(len(good_chars)))\n",
    "# model.add(Activation('softmax'))\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.01), metrics=['accuracy'])\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(256, input_shape=(seed_len, len(good_chars))))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(len(good_chars), activation='softmax'))\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(seed_len, len(good_chars)), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(good_chars), activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 100, 256)          293888    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100, 256)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30)                7710      \n",
      "=================================================================\n",
      "Total params: 826,910\n",
      "Trainable params: 826,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_prediction(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 331956 samples, validate on 82990 samples\n",
      "Epoch 1/50\n",
      "227776/331956 [===================>..........] - ETA: 51:31 - loss: 2.0265 - accuracy: 0.3999"
     ]
    }
   ],
   "source": [
    "train_len = int(x.shape[0] * 0.8)\n",
    "\n",
    "x_train = x[:train_len, :, :]\n",
    "y_train = y[:train_len, :]\n",
    "\n",
    "x_test = x[train_len:, :, :]\n",
    "y_test = y[train_len:, :]\n",
    "\n",
    "# history = model.fit(x_train, y_train, batch_size=128, epochs=5, validation_data = (x_test, y_test))\n",
    "# history = model.fit(x_train, y_train, epochs=20, batch_size=128, validation_data = (x_test, y_test))\n",
    "history = model.fit(x_train, y_train, epochs=50, batch_size=64, validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output(size=400):\n",
    "    generated = ''\n",
    "    usr_input = input(\"Input a phrase to use for generation: \")\n",
    "\n",
    "    seed = ('{0:0>' + str(seed_len) + '}').format(usr_input).lower()\n",
    "    generated += usr_input \n",
    "\n",
    "    print(\"\\n\\nHere is your song: \\n\\n\") \n",
    "    print(usr_input, end='')\n",
    "    \n",
    "    for i in range(size):\n",
    "        x_pred = np.zeros((1, seed_len, len(good_chars)))\n",
    "\n",
    "        for t, char in enumerate(seed):\n",
    "            if char != '0':\n",
    "                x_pred[0, t, char_to_int[char]] = 1.\n",
    "\n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        output_index = read_prediction(preds, temperature = 0.2)\n",
    "        output = int_to_char[output_index]\n",
    "\n",
    "        generated += output\n",
    "        seed = seed[1:] + output\n",
    "\n",
    "        print(output, end='')\n",
    "\n",
    "        if output == '\\n':\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Models/model_' + artist.lower().replace(' ', '_')\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(filename + '.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(filename + '.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
